### ✅ **Affinity & Anti-Affinity in Kubernetes**

Affinity and Anti-Affinity are advanced scheduling features that **control how Pods are placed on Nodes** or **relative to other Pods**, using **expressions** (unlike `nodeSelector`, which is exact match only).

---

## ✅ **Types of Affinity**

### **1. Node Affinity**

* **Pod → Node relationship**
* Similar to `nodeSelector` but more powerful (supports operators and soft rules).
* Two types:

  * `requiredDuringSchedulingIgnoredDuringExecution` → **Hard rule** (must match).
  * `preferredDuringSchedulingIgnoredDuringExecution` → **Soft rule** (scheduler tries to match, but not mandatory).

**Example:**

```yaml
affinity:
  nodeAffinity:
    requiredDuringSchedulingIgnoredDuringExecution:
      nodeSelectorTerms:
      - matchExpressions:
        - key: disktype
          operator: In
          values:
          - ssd
```

→ Pod **must** run on nodes with `disktype=ssd`.

---

### **2. Pod Affinity**

* **Pod → Pod relationship**
* Tells scheduler to **place this Pod close to (same node, zone, etc.) another Pod** that has specific labels.

**Example:**

```yaml
affinity:
  podAffinity:
    requiredDuringSchedulingIgnoredDuringExecution:
      labelSelector:
        matchExpressions:
        - key: app
          operator: In
          values:
          - frontend
      topologyKey: "kubernetes.io/hostname"
```

→ Pod should be on the **same node** as Pods labeled `app=frontend`.

---

### **3. Pod Anti-Affinity**

* Opposite of Pod Affinity.
* Tells scheduler to **avoid placing this Pod near certain Pods**.

**Example:**

```yaml
affinity:
  podAntiAffinity:
    requiredDuringSchedulingIgnoredDuringExecution:
      labelSelector:
        matchExpressions:
        - key: app
          operator: In
          values:
          - frontend
      topologyKey: "kubernetes.io/hostname"
```

→ Do **NOT** place this Pod on the **same node** as Pods labeled `app=frontend`.

---

## ✅ **Why Use Affinity & Anti-Affinity?**

* High availability → Spread replicas across nodes.
* Reduce **single point of failure**.
* Place services together for **low latency**.
* Avoid running two heavy Pods on the same node.

---

### ✅ **Key Differences**

| Feature         | nodeSelector | Node Affinity           |
| --------------- | ------------ | ----------------------- |
| Operators       | Only `=`     | `In`, `NotIn`, `Exists` |
| Hard/Soft rules | Only Hard    | Hard & Soft             |

---

✅ **Diagram** (Affinity vs Anti-Affinity)

```
+-----------+    +-----------+
|  Node 1   |    |  Node 2   |
| frontend  |    | backend   |
+-----------+    +-----------+
      ↑              ↑
  Pod Affinity: Keep pods together
  Pod Anti-Affinity: Keep pods apart
```

# Example 
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: with-affinity-preferred-weight
  labels:
    app: example
spec:
  replicas: 2
  selector:
    matchLabels:
      app: example
  template:
    metadata:
      labels:
        app: example
    spec:
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: kubernetes.io/os
                operator: In
                values:
                - linux
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 1
            preference:
              matchExpressions:
              - key: weight
                operator: In
                values:
                - hello
          - weight: 50
            preference:
              matchExpressions:
              - key: height
                operator: In
                values:
                - hi
      containers:
      - name: with-node-affinity
        image: registry.k8s.io/pause:3.8
```
---

### ✅ **Resource Type**

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: with-affinity-preferred-weight
```

* This creates a **Pod** named `with-affinity-preferred-weight`.

---

### ✅ **Affinity Section**

This is where **Node Affinity** rules are defined.

---

#### **1. Hard Rule (Required)**

```yaml
requiredDuringSchedulingIgnoredDuringExecution:
  nodeSelectorTerms:
  - matchExpressions:
    - key: kubernetes.io/os
      operator: In
      values:
      - linux
```

* **Meaning:**

  * Pod can **only** run on Nodes with:

    ```
    kubernetes.io/os = linux
    ```
  * This is a **hard constraint** (mandatory).
* If no Node has this label, Pod will stay in **Pending**.

---

#### **2. Soft Rules (Preferred)**

```yaml
preferredDuringSchedulingIgnoredDuringExecution:
- weight: 1
  preference:
    matchExpressions:
    - key: label-1
      operator: In
      values:
      - key-1
- weight: 50
  preference:
    matchExpressions:
    - key: label-2
      operator: In
      values:
      - key-2
```

* **Soft preference** means:

  * The scheduler **tries to honor these**, but it's not mandatory.
  * If multiple Nodes satisfy the hard rule, Kubernetes uses **weights** to pick the best node.

* Here:

  * **First preference**:

    * If Node has `label-1=key-1`, add **1 point**.
  * **Second preference**:

    * If Node has `label-2=key-2`, add **50 points**.
  * Node with the **highest total score** wins.

---

### ✅ **Container Section**

```yaml
containers:
- name: with-node-affinity
  image: registry.k8s.io/pause:3.8
```

* Just a placeholder container (pause image).

---

### ✅ **Scheduling Logic**

1. Scheduler looks for Nodes that **must match** `kubernetes.io/os=linux`.
2. Among those Nodes:

   * If a Node has `label-1=key-1` → +1 score.
   * If a Node has `label-2=key-2` → +50 score.
3. Node with **maximum weight** will be selected.

---

### ✅ **Example**

* Node A: `kubernetes.io/os=linux`, `label-1=key-1`

  * Score = 1
* Node B: `kubernetes.io/os=linux`, `label-2=key-2`

  * Score = 50
* Node C: `kubernetes.io/os=linux`, `label-1=key-1`, `label-2=key-2`

  * Score = 51 → **Pod scheduled here**.

---

### ✅ **Key Points**

* `requiredDuringSchedulingIgnoredDuringExecution` → **must match**.
* `preferredDuringSchedulingIgnoredDuringExecution` → **ranking with weights**.
* Higher weight = **higher priority** in scheduling decision.
* If no soft match, Pod will still schedule on any node that satisfies **hard rule**.

---

### ✅ **Stage 1 – Hard Rules First**

* `requiredDuringSchedulingIgnoredDuringExecution` is **mandatory**.
* The scheduler **filters nodes** based on these hard rules.
* If **no node satisfies hard rules**, the pod remains **Pending forever** (soft rules are ignored completely).

---

### ✅ **Stage 2 – Apply Soft Rules on Filtered Nodes**

* After filtering, the scheduler applies `preferredDuringSchedulingIgnoredDuringExecution` on the **remaining nodes**.
* It **calculates the total weight** for each node and **picks the one with the highest score**.

---

### ✅ **Important Point**

* Soft rules **only come into play if hard rules are satisfied**.
* If **only one node passes hard rules**, the scheduler will place the pod there even if it has **zero soft rule matches**.

---

### ✅ **Example with Both**

Imagine:

* **Hard rule:** `kubernetes.io/os = linux`
* **Soft rules:**

  * `label-1=key-1` → weight 1
  * `label-2=key-2` → weight 50

Nodes:

* Node A: `os=linux`, `label-1=key-1`
* Node B: `os=linux`, `label-2=key-2`
* Node C: `os=windows`, `label-2=key-2`

Process:

1. Hard rule → Only **Node A & Node B** remain (Node C is out because `os=windows`).
2. Soft rules →

   * Node A = 1 point
   * Node B = 50 points
3. Pod scheduled on **Node B**.

---

✅ So yes, **hard and soft rules work together**, but **priority is hard > soft**.

---

### ✅ Conditions from Pod Spec

* **Hard rule**: `kubernetes.io/os=linux`
* **Soft rules (weights)**:

  * `label-1=key-1` → weight **1**
  * `label-2=key-2` → weight **50**

---

### ✅ Nodes Info:

* **node-1**: `kubernetes.io/os=linux`, `label-1=key-1`
* **node-2**: `kubernetes.io/os=linux`, `label-1=key-1`
* **node-3**: `kubernetes.io/os=linux`, `label-2=key-2`

---

### ✅ Step 1: Apply **Hard Rule**

All three nodes match `kubernetes.io/os=linux`.
So **node-1, node-2, node-3 remain in the candidate list**.

---

### ✅ Step 2: Apply **Soft Rules (Score Calculation)**

Kube-scheduler calculates scores for each node:

| Node   | Matches `label-1=key-1` (weight 1) | Matches `label-2=key-2` (weight 50) | Total Score |
| ------ | ---------------------------------- | ----------------------------------- | ----------- |
| node-1 | ✅ (1)                              | ❌ (0)                               | **1**       |
| node-2 | ✅ (1)                              | ❌ (0)                               | **1**       |
| node-3 | ❌ (0)                              | ✅ (50)                              | **50**      |

---

### ✅ Step 3: Pick Highest Score

* **node-3 wins** because it has the highest total score (50).
* Pod is scheduled on **node-3**.

---

### ✅ Visual Diagram:

```
           [Hard Rule Filter]
       +---------------------------------+
       |  node-1   node-2   node-3      |
       +---------------------------------+
                   ↓
           [Soft Rule Scoring]
       node-1 → score = 1
       node-2 → score = 1
       node-3 → score = 50
                   ↓
           [Scheduler Decision]
       Pod → node-3 (highest score)
```

---

✅ **Summary:**

* Hard rules **filter** the nodes.
* Soft rules **rank** the filtered nodes.
* Highest score wins.

---

# Exercise

Here’s how you can turn this into a **practical exercise** to understand **Node Affinity with required and preferred rules (with weights)**:

---

### ✅ **Exercise: Test Node Affinity with Required & Preferred Rules**

---

#### **Step 1: Prepare Your Nodes**

Label your nodes with the following:

```bash
# For node-1
kubectl label node node-1 disk-type=ssd
kubectl label node node-1 weight=hello

# For node-2
kubectl label node node-2 disk-type=ssd
kubectl label node node-2 height=hi

# For node-3
kubectl label node node-3 disk-type=ssd
kubectl label node node-3 height=hi
```

✔ All 3 nodes have **disk-type=ssd** (required rule).
✔ node-1 has **weight=hello**.
✔ node-2 and node-3 have **height=hi**.

---

#### **Step 2: Apply Deployment with Node Affinity**

Create a file named **`node-affinity-deployment.yaml`**:

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: with-affinity-preferred-weight
  labels:
    app: example
spec:
  replicas: 2
  selector:
    matchLabels:
      app: example
  template:
    metadata:
      labels:
        app: example
    spec:
      affinity:
        nodeAffinity:
          # Required rule: Pod must go to a node with disk-type=ssd
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: disk-type
                operator: In
                values:
                - ssd
          # Preferred rules: Weighted scoring
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 1
            preference:
              matchExpressions:
              - key: weight
                operator: In
                values:
                - hello
          - weight: 50
            preference:
              matchExpressions:
              - key: height
                operator: In
                values:
                - hi
      containers:
      - name: with-node-affinity
        image: registry.k8s.io/pause:3.8
```

Apply it:

```bash
kubectl apply -f node-affinity-deployment.yaml
```

---

#### **Step 3: Check Pod Scheduling**

```bash
kubectl get pods -o wide
```

✔ All nodes meet the **required** condition (`disk-type=ssd`), so pods can go to any of them.
✔ Scheduler will **prefer nodes with highest weight sum**:

* node-1 → weight=hello (weight 1)
* node-2 → height=hi (weight 50)
* node-3 → height=hi (weight 50)

**Expected result:** Pods will likely schedule on **node-2** and **node-3** (because weight 50 > weight 1).

---

#### **Step 4: Test Behavior**

* Try removing the **height** label from node-2 and node-3:

  ```bash
  kubectl label node node-2 height-
  kubectl label node node-3 height-
  ```
* Then delete pods:

  ```bash
  kubectl delete pod -l app=example
  ```
* See where they go → now node-1 will win because it has the only preferred label.

---

✅ This exercise helps you **practice node affinity with required + preferred rules and weight impact**.

---

Do you want me to **create 2 more advanced exercises** for:
✔ Taint + Tolerations with Affinity
✔ Combining Node Affinity with Pod Affinity & Anti-Affinity?
